{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataAnalysis1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyO4hmrFx63egdNWY/J8RF21",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajputankur56/DataAnalysis/blob/master/DataAnalysis1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5faWnxhGNpOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNE4v82LEBKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Load data set here\n",
        "df = pd.read_csv(\"FilePath\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT66hMCmD5oA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Data Analysis 1\n",
        "print(\"DF Head : 10 Rows \")\n",
        "#print(df.head(10))\n",
        "\n",
        "print(\"DF Tail : 10 Rows\")\n",
        "#print(df.tail(10))\n",
        "\n",
        "print(\"DF Describe\")\n",
        "#print(df.describe())\n",
        "\n",
        "print(\"DF info\")\n",
        "#print(df.info())\n",
        "\n",
        "print(\"Sorted by Target Variable\")\n",
        "#print(df.sort_values(\"MEDV\"))\n",
        "\n",
        "### counting a categorical values number of occurence\n",
        "#print(\"Unique values\")\n",
        "#print(df['Category1'].value_counts())\n",
        "#print(\"Total unique values for every column\")\n",
        "#print(df.nunique())\n",
        "\n",
        "### change data type of a column\n",
        "# df[\"Col1\"] = df[\"Col1\"].astype(\"category\")\n",
        "#print(df[\"Col1\"].dtype)\n",
        "\n",
        "### Filtering on condition\n",
        "#print(df[\"RM\"] <= 5.5)\n",
        "#print(df[df[\"RM\"] <= 5.5].sort_values(\"RM\"))\n",
        "\n",
        "## Filtering null values\n",
        "## print(to check if any column has null values)\n",
        "#print(df.isnull().sum())\n",
        "\n",
        "### Fill missing values\n",
        "\n",
        "## 1 Remove all rows with null values\n",
        "#df.dropna()\n",
        "#df.dropna(subset = [\"Col1\",\"Col2\"],inplace = True)\n",
        "\n",
        "## 2 Fill missing value with mean,median using fillna\n",
        "#df[\"Col1\"] = df[\"Col1\"].fillna(df[\"Col1\"].median())\n",
        "\n",
        "### print(\"Dropping Duplicates\")\n",
        "#print(df.shape)\n",
        "#duplicate_row = df[df.duplicated()]\n",
        "#print(\"number of Duplicate rows : \",duplicate_row.shape)\n",
        "# dropped_duplicate = df.drop_duplicates()\n",
        "\n",
        "\n",
        "### Round up Column value\n",
        "df[\"MEDV\"] = df[\"MEDV\"].round(2)\n",
        "\n",
        "## Set precision\n",
        "pd.set_option(\"display.precision\",5)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7J4PP9xSNm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Data Analysis 2\n",
        "\n",
        "## print(\"Distribution on Target Variable\")\n",
        "#print(df[\"MEDV\"].describe())\n",
        "#plt.figure(figsize=(9,8))\n",
        "#sns.distplot(df[\"MEDV\"],color='g',bins=100,hist_kws={'alpha':0.4})\n",
        "### always check for normal distribution if you found outlier in distribution then you need to remove those instace to get \n",
        "### nonrmal Distribution\n",
        "\n",
        "### print(\"Numerical Data Distribution\")\n",
        "### select only column with numerical data\n",
        "# set(df.dtypes.tolist())\n",
        "# df_num = df.select_dtypes(include = [\"float64\",\"int64\"])\n",
        "# df_num.hist(figsize = (16,20), bins = 50, xlabelsize=8,ylabelsize=8)\n",
        "\n",
        "### print(\"Correlations\")\n",
        "# df_num_corr = df_num.corr()[\"Target Feature\"][:-1] ## to get correlation for target var\n",
        "# df_num_corr = df_num.corr()[\"MEDV\"][:-1] ## to get correlation for target var\n",
        "\n",
        "# good_correlator = df_num_corr[abs(df_num_corr) >= 0.5].sort_values(ascending = False)\n",
        "# print(\"There is {} strongly correlated values with SalePrice:\\n{}\".format(len(good_correlator), good_correlator))\n",
        "\n",
        "#sns.heatmap(df_num.corr(),cmap='viridis',vmax=1.0,vmin=-1.0,linewidth=0.1,annot=True,annot_kws={'size':8},square=True)\n",
        "\n",
        "'''\n",
        "Perfect, we now have a list of strongly correlated values but this list is incomplete as we know that correlation is affected by outliers. So we could proceed as follow:\n",
        "\n",
        "Plot the numerical features and see which ones have very few or explainable outliers\n",
        "Remove the outliers from these features and see which one can have a good correlation without their outliers\n",
        "Btw, correlation by itself does not always explain the relationship between data so ploting them could even lead us to new insights and in the same manner, check that our correlated values have a linear relationship to the Target.\n",
        "\n",
        "For example, relationships such as curvilinear relationship cannot be guessed just by looking at the correlation value so lets take the features we excluded from our correlation table and plot them to see if they show some kind of pattern.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "# for i in range(0, len(df_num), 1):\n",
        "#     g = sns.pairplot(data=df_num,\n",
        "#                 x_vars=df_num.columns[i:i+1],\n",
        "#                  y_vars = [\"MEDV\"],height=10, aspect=0.6\n",
        "#                  #y_vars = df[\"TARGET\"]\n",
        "#                 )\n",
        "#     g.fig.set_size_inches(4,4)\n",
        "\n",
        "'''\n",
        "We can clearly identify some relationships. Most of them seems to have a linear relationship with the SalePrice and if we look closely at the data we can see that a lot of data points are located on x = 0 which may indicate the absence of such feature in the house.\n",
        "'''\n",
        "\n",
        "# ###lets remove these 0 values and repeat the process of finding correlated values\n",
        "# import operator\n",
        "\n",
        "# individual_features_df = []\n",
        "# for i in range(0, len(df_num.columns) - 1): # -1 because the last column is SalePrice\n",
        "#     tmpDf = df_num[[df_num.columns[i], 'SalePrice']]\n",
        "#     tmpDf = tmpDf[tmpDf[df_num.columns[i]] != 0]\n",
        "#     individual_features_df.append(tmpDf)\n",
        "\n",
        "# all_correlations = {feature.columns[0]: feature.corr()['SalePrice'][0] for feature in individual_features_df}\n",
        "# all_correlations = sorted(all_correlations.items(), key=operator.itemgetter(1))\n",
        "# for (key, value) in all_correlations:\n",
        "#     print(\"{:>15}: {:>15}\".format(key, value))\n",
        "\n",
        "# golden_features_list = [key for key, value in all_correlations if abs(value) >= 0.5]\n",
        "# print(\"There is {} strongly correlated values with SalePrice:\\n{}\".format(len(golden_features_list), golden_features_list))\n",
        "\n",
        "### feature to feature realation ship\n",
        "### this help to merge two very correlated feature into one that makes execution fast/\n",
        "\n",
        "# corr = df_num.drop('MEDV', axis=1).corr() # We already examined SalePrice correlations\n",
        "# plt.figure(figsize=(12, 10))\n",
        "\n",
        "# sns.heatmap(corr, \n",
        "#             cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
        "#             annot=True, annot_kws={\"size\": 8}, square=True);\n",
        "\n",
        "\n",
        "### Quantitative to Quantitative Relation\n",
        "\n",
        "# take all quantative column in a list\n",
        "# quan_list = ['RM','LSTAT','PTRATIO','MEDV']\n",
        "\n",
        "# df_quan = df[quan_list]\n",
        "# df_quan.head()\n",
        "\n",
        "## select only good correlator for Q -> Q analysis\n",
        "# features_to_analyse = [x for x in quantitative_features_list if x in golden_features_list]\n",
        "# features_to_analyse.append('MEDV')\n",
        "# features_to_analyse\n",
        "\n",
        "# fig , ax = plt.subplots(round(len(quan_list)/3),3,figsize=(15,12))\n",
        "# for i,ax in enumerate(fig.axes):\n",
        "#     if i<len(quan_list)-1:\n",
        "#         sns.regplot(data = df_quan,x=quan_list[i],y='MEDV',ax=ax)\n",
        "\n",
        "### Categorical to Quantitative Relationship\n",
        "## pick only categorical column based on quantative columns\n",
        "# quantitative_features_list[:-1] as the last column is SalePrice and we want to keep it\n",
        "# categorical_features = [a for a in quantitative_features_list[:-1] + df.columns.tolist() if (a not in quantitative_features_list[:-1]) or (a not in df.columns.tolist())]\n",
        "# df_categ = df[categorical_features]\n",
        "# df_categ.head()\n",
        "\n",
        "# df_not_num = df_categ.select_dtypes(include = ['O'])\n",
        "# print('There is {} non numerical features including:\\n{}'.format(len(df_not_num.columns), df_not_num.columns.tolist()))\n",
        "\n",
        "## plot category to target in a box plot\n",
        "# plt.figure(figsize = (10, 6))\n",
        "# ax = sns.boxplot(x='BsmtExposure', y='SalePrice', data=df_categ)\n",
        "# plt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\n",
        "# plt.xticks(rotation=45)\n",
        "\n",
        "### check distribution of categorical variable\n",
        "\n",
        "# fig, axes = plt.subplots(round(len(df_not_num.columns) / 3), 3, figsize=(12, 30))\n",
        "\n",
        "# for i, ax in enumerate(fig.axes):\n",
        "#     if i < len(df_not_num.columns):\n",
        "#         ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)\n",
        "#         sns.countplot(x=df_not_num.columns[i], alpha=0.7, data=df_not_num, ax=ax)\n",
        "\n",
        "# fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}